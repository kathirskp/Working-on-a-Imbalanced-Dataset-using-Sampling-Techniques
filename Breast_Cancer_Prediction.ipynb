{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used is a unbalanced dataset. Here i'm going to explain how to standardized variable, how to create PCA and how to work on unbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "data=pd.read_csv(\"K:\\ML\\Github\\Breast_Cancer\\Breast_Cancer_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "diagnosis                  0\n",
       "radius_mean                0\n",
       "texture_mean               0\n",
       "perimeter_mean             0\n",
       "area_mean                  0\n",
       "smoothness_mean            0\n",
       "compactness_mean           0\n",
       "concavity_mean             0\n",
       "concave points_mean        0\n",
       "symmetry_mean              0\n",
       "fractal_dimension_mean     0\n",
       "radius_se                  0\n",
       "texture_se                 0\n",
       "perimeter_se               0\n",
       "area_se                    0\n",
       "smoothness_se              0\n",
       "compactness_se             0\n",
       "concavity_se               0\n",
       "concave points_se          0\n",
       "symmetry_se                0\n",
       "fractal_dimension_se       0\n",
       "radius_worst               0\n",
       "texture_worst              0\n",
       "perimeter_worst            0\n",
       "area_worst                 0\n",
       "smoothness_worst           0\n",
       "compactness_worst          0\n",
       "concavity_worst            0\n",
       "concave points_worst       0\n",
       "symmetry_worst             0\n",
       "fractal_dimension_worst    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "#checking for any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>0</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>0</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>0</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>0</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302          1        17.99         10.38          122.80     1001.0   \n",
       "1    842517          0        20.57         17.77          132.90     1326.0   \n",
       "2  84300903          0        19.69         21.25          130.00     1203.0   \n",
       "3  84348301          0        11.42         20.38           77.58      386.1   \n",
       "4  84358402          0        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "#there are total 32 columns.\n",
    "#As we can see, all Variables are not standardized. Some are 0's and some are in 100's\n",
    "#PCA will be affected, if our variables are not scaled to same level\n",
    "#Target variable is \"target\", where 0 means \"Fraud\" and 1 means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>0.052724</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.991511</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>0.223679</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.300487</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id   diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "count  5.690000e+02  569.000000   569.000000    569.000000      569.000000   \n",
       "mean   3.037183e+07    0.052724    14.127292     19.289649       91.991511   \n",
       "std    1.250206e+08    0.223679     3.524049      4.301036       24.300487   \n",
       "min    8.670000e+03    0.000000     6.981000      9.710000       43.790000   \n",
       "25%    8.692180e+05    0.000000    11.700000     16.170000       75.170000   \n",
       "50%    9.060240e+05    0.000000    13.370000     18.840000       86.240000   \n",
       "75%    8.813129e+06    0.000000    15.780000     21.800000      104.100000   \n",
       "max    9.113205e+08    1.000000    28.110000     39.280000      188.500000   \n",
       "\n",
       "         area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "count   569.000000       569.000000        569.000000      569.000000   \n",
       "mean    654.889104         0.096360          0.104341        0.088799   \n",
       "std     351.914129         0.014064          0.052813        0.079720   \n",
       "min     143.500000         0.052630          0.019380        0.000000   \n",
       "25%     420.300000         0.086370          0.064920        0.029560   \n",
       "50%     551.100000         0.095870          0.092630        0.061540   \n",
       "75%     782.700000         0.105300          0.130400        0.130700   \n",
       "max    2501.000000         0.163400          0.345400        0.426800   \n",
       "\n",
       "       concave points_mean           ...             radius_worst  \\\n",
       "count           569.000000           ...               569.000000   \n",
       "mean              0.048919           ...                16.269190   \n",
       "std               0.038803           ...                 4.833242   \n",
       "min               0.000000           ...                 7.930000   \n",
       "25%               0.020310           ...                13.010000   \n",
       "50%               0.033500           ...                14.970000   \n",
       "75%               0.074000           ...                18.790000   \n",
       "max               0.201200           ...                36.040000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try to learn more about the data.\n",
    "#Target variable is the 'Class' variable, where 0 means 'fraudulent' and 1 means 'genuine'\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0L: 539, 1L: 30})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check the distribution of the target variable 'Class'\n",
    "Counter(data['diagnosis'])\n",
    "\n",
    "#This is the example of highly imbalanced dataset\n",
    "#Where proportion of 1 is very less compared to 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_target = pd.value_counts(data['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,u'Target Class')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xb602390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "count_target.plot(kind='bar')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Target Class')\n",
    "\n",
    "#Where proportion of 1 is very less compared to 0's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets standardize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column \"ID\" is not important, let's drop it\n",
    "data = data.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the target column in separate DF\n",
    "target=data['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the target variable, to create PC for ramining variables\n",
    "data_var = data.drop(['diagnosis'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'radius_mean', u'texture_mean', u'perimeter_mean', u'area_mean',\n",
       "       u'smoothness_mean', u'compactness_mean', u'concavity_mean',\n",
       "       u'concave points_mean', u'symmetry_mean', u'fractal_dimension_mean',\n",
       "       u'radius_se', u'texture_se', u'perimeter_se', u'area_se',\n",
       "       u'smoothness_se', u'compactness_se', u'concavity_se',\n",
       "       u'concave points_se', u'symmetry_se', u'fractal_dimension_se',\n",
       "       u'radius_worst', u'texture_worst', u'perimeter_worst', u'area_worst',\n",
       "       u'smoothness_worst', u'compactness_worst', u'concavity_worst',\n",
       "       u'concave points_worst', u'symmetry_worst', u'fractal_dimension_worst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=data_var.columns\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the all the variables to same level\n",
    "data_std=sc.fit_transform(data[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=pd.DataFrame(data=data_std, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final=pd.concat([data_final,target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.268929</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>2.255747</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.684924</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>-0.868652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.565480</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>-0.398008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.593576</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>4.910919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.775537</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>-0.562450</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0     1.097064     -2.073335        1.268929   0.984375         1.568466   \n",
       "1     1.829821     -0.353632        1.684924   1.908708        -0.826962   \n",
       "2     1.579888      0.456187        1.565480   1.558884         0.942210   \n",
       "3    -0.768909      0.253732       -0.593576  -0.764464         3.283553   \n",
       "4     1.750297     -1.151816        1.775537   1.826229         0.280372   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0          3.283515        2.652874             2.532475       2.217515   \n",
       "1         -0.487072       -0.023846             0.548144       0.001392   \n",
       "2          1.052926        1.363478             2.037231       0.939685   \n",
       "3          3.402909        1.915897             1.451707       2.867383   \n",
       "4          0.539340        1.371011             1.428493      -0.009560   \n",
       "\n",
       "   fractal_dimension_mean    ...      texture_worst  perimeter_worst  \\\n",
       "0                2.255747    ...          -1.359293         2.303601   \n",
       "1               -0.868652    ...          -0.369203         1.535126   \n",
       "2               -0.398008    ...          -0.023974         1.347475   \n",
       "3                4.910919    ...           0.133984        -0.249939   \n",
       "4               -0.562450    ...          -1.466770         1.338539   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0    2.001237          1.307686           2.616665         2.109526   \n",
       "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
       "2    1.456285          0.527407           1.082932         0.854974   \n",
       "3   -0.550021          3.394275           3.893397         1.989588   \n",
       "4    1.220724          0.220556          -0.313395         0.613179   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  diagnosis  \n",
       "0              2.296076        2.750622                 1.937015          1  \n",
       "1              1.087084       -0.243890                 0.281190          0  \n",
       "2              1.955000        1.152255                 0.201391          0  \n",
       "3              2.175786        6.046041                 4.935010          0  \n",
       "4              0.729259       -0.868353                -0.397100          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From 32 columns i'm creating 10 principal components \"PC1 ot PC10\"\n",
    "pca = PCA(n_components=10)\n",
    "principalComponents = pca.fit_transform(data_std)\n",
    "data_pca = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the PC and target variables into single DF\n",
    "data_final=pd.concat([data_pca,target],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192787</td>\n",
       "      <td>1.948495</td>\n",
       "      <td>-1.123134</td>\n",
       "      <td>3.633519</td>\n",
       "      <td>-1.196361</td>\n",
       "      <td>1.411751</td>\n",
       "      <td>2.158566</td>\n",
       "      <td>-0.398437</td>\n",
       "      <td>-0.156939</td>\n",
       "      <td>-0.877211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.387372</td>\n",
       "      <td>-3.768254</td>\n",
       "      <td>-0.529212</td>\n",
       "      <td>1.118284</td>\n",
       "      <td>0.621436</td>\n",
       "      <td>0.028609</td>\n",
       "      <td>0.013702</td>\n",
       "      <td>0.240727</td>\n",
       "      <td>-0.711836</td>\n",
       "      <td>1.107150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.733607</td>\n",
       "      <td>-1.075201</td>\n",
       "      <td>-0.551674</td>\n",
       "      <td>0.911994</td>\n",
       "      <td>-0.177461</td>\n",
       "      <td>0.541477</td>\n",
       "      <td>-0.668310</td>\n",
       "      <td>0.097385</td>\n",
       "      <td>0.024045</td>\n",
       "      <td>0.454678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.123148</td>\n",
       "      <td>10.275538</td>\n",
       "      <td>-3.233084</td>\n",
       "      <td>0.152239</td>\n",
       "      <td>-2.960113</td>\n",
       "      <td>3.053563</td>\n",
       "      <td>1.428807</td>\n",
       "      <td>1.058830</td>\n",
       "      <td>-1.408256</td>\n",
       "      <td>-1.116101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.934887</td>\n",
       "      <td>-1.948179</td>\n",
       "      <td>1.389734</td>\n",
       "      <td>2.940752</td>\n",
       "      <td>0.546273</td>\n",
       "      <td>-1.226569</td>\n",
       "      <td>-0.935868</td>\n",
       "      <td>0.636294</td>\n",
       "      <td>-0.263878</td>\n",
       "      <td>0.377590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1        PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
       "0  9.192787   1.948495 -1.123134  3.633519 -1.196361  1.411751  2.158566   \n",
       "1  2.387372  -3.768254 -0.529212  1.118284  0.621436  0.028609  0.013702   \n",
       "2  5.733607  -1.075201 -0.551674  0.911994 -0.177461  0.541477 -0.668310   \n",
       "3  7.123148  10.275538 -3.233084  0.152239 -2.960113  3.053563  1.428807   \n",
       "4  3.934887  -1.948179  1.389734  2.940752  0.546273 -1.226569 -0.935868   \n",
       "\n",
       "        PC8       PC9      PC10  diagnosis  \n",
       "0 -0.398437 -0.156939 -0.877211          1  \n",
       "1  0.240727 -0.711836  1.107150          0  \n",
       "2  0.097385  0.024045  0.454678          0  \n",
       "3  1.058830 -1.408256 -1.116101          0  \n",
       "4  0.636294 -0.263878  0.377590          0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The final DF will have 10 Principal components and 1 target varible\n",
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.277987e-17</td>\n",
       "      <td>-9.658355e-17</td>\n",
       "      <td>4.292602e-17</td>\n",
       "      <td>-1.248757e-16</td>\n",
       "      <td>-7.316936e-19</td>\n",
       "      <td>2.575561e-17</td>\n",
       "      <td>-5.619407e-17</td>\n",
       "      <td>2.887751e-17</td>\n",
       "      <td>1.404852e-17</td>\n",
       "      <td>-7.915705e-17</td>\n",
       "      <td>0.052724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.647410e+00</td>\n",
       "      <td>2.387894e+00</td>\n",
       "      <td>1.680154e+00</td>\n",
       "      <td>1.408596e+00</td>\n",
       "      <td>1.285198e+00</td>\n",
       "      <td>1.099761e+00</td>\n",
       "      <td>8.223866e-01</td>\n",
       "      <td>6.909837e-01</td>\n",
       "      <td>6.464175e-01</td>\n",
       "      <td>5.926851e-01</td>\n",
       "      <td>0.223679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-5.565961e+00</td>\n",
       "      <td>-7.775516e+00</td>\n",
       "      <td>-4.880458e+00</td>\n",
       "      <td>-5.134082e+00</td>\n",
       "      <td>-4.788509e+00</td>\n",
       "      <td>-4.218172e+00</td>\n",
       "      <td>-4.083853e+00</td>\n",
       "      <td>-3.953902e+00</td>\n",
       "      <td>-2.968986e+00</td>\n",
       "      <td>-2.738943e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-2.757652e+00</td>\n",
       "      <td>-1.499750e+00</td>\n",
       "      <td>-1.016977e+00</td>\n",
       "      <td>-7.865539e-01</td>\n",
       "      <td>-6.160854e-01</td>\n",
       "      <td>-7.280749e-01</td>\n",
       "      <td>-4.481320e-01</td>\n",
       "      <td>-3.731416e-01</td>\n",
       "      <td>-3.238127e-01</td>\n",
       "      <td>-3.664669e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.174111e+00</td>\n",
       "      <td>-1.959114e-01</td>\n",
       "      <td>-1.554947e-01</td>\n",
       "      <td>1.153786e-01</td>\n",
       "      <td>-2.882584e-02</td>\n",
       "      <td>-7.245343e-02</td>\n",
       "      <td>-1.761688e-02</td>\n",
       "      <td>1.366888e-02</td>\n",
       "      <td>1.235559e-02</td>\n",
       "      <td>2.487666e-03</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.508592e+00</td>\n",
       "      <td>1.228054e+00</td>\n",
       "      <td>8.570429e-01</td>\n",
       "      <td>9.700354e-01</td>\n",
       "      <td>6.105040e-01</td>\n",
       "      <td>6.170852e-01</td>\n",
       "      <td>4.541210e-01</td>\n",
       "      <td>3.497753e-01</td>\n",
       "      <td>3.622343e-01</td>\n",
       "      <td>3.263119e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.631891e+01</td>\n",
       "      <td>1.257291e+01</td>\n",
       "      <td>1.011290e+01</td>\n",
       "      <td>5.193602e+00</td>\n",
       "      <td>7.490922e+00</td>\n",
       "      <td>5.134282e+00</td>\n",
       "      <td>5.416337e+00</td>\n",
       "      <td>4.362065e+00</td>\n",
       "      <td>3.783534e+00</td>\n",
       "      <td>3.192173e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                PC1           PC2           PC3           PC4           PC5  \\\n",
       "count  5.690000e+02  5.690000e+02  5.690000e+02  5.690000e+02  5.690000e+02   \n",
       "mean   3.277987e-17 -9.658355e-17  4.292602e-17 -1.248757e-16 -7.316936e-19   \n",
       "std    3.647410e+00  2.387894e+00  1.680154e+00  1.408596e+00  1.285198e+00   \n",
       "min   -5.565961e+00 -7.775516e+00 -4.880458e+00 -5.134082e+00 -4.788509e+00   \n",
       "25%   -2.757652e+00 -1.499750e+00 -1.016977e+00 -7.865539e-01 -6.160854e-01   \n",
       "50%   -1.174111e+00 -1.959114e-01 -1.554947e-01  1.153786e-01 -2.882584e-02   \n",
       "75%    2.508592e+00  1.228054e+00  8.570429e-01  9.700354e-01  6.105040e-01   \n",
       "max    1.631891e+01  1.257291e+01  1.011290e+01  5.193602e+00  7.490922e+00   \n",
       "\n",
       "                PC6           PC7           PC8           PC9          PC10  \\\n",
       "count  5.690000e+02  5.690000e+02  5.690000e+02  5.690000e+02  5.690000e+02   \n",
       "mean   2.575561e-17 -5.619407e-17  2.887751e-17  1.404852e-17 -7.915705e-17   \n",
       "std    1.099761e+00  8.223866e-01  6.909837e-01  6.464175e-01  5.926851e-01   \n",
       "min   -4.218172e+00 -4.083853e+00 -3.953902e+00 -2.968986e+00 -2.738943e+00   \n",
       "25%   -7.280749e-01 -4.481320e-01 -3.731416e-01 -3.238127e-01 -3.664669e-01   \n",
       "50%   -7.245343e-02 -1.761688e-02  1.366888e-02  1.235559e-02  2.487666e-03   \n",
       "75%    6.170852e-01  4.541210e-01  3.497753e-01  3.622343e-01  3.263119e-01   \n",
       "max    5.134282e+00  5.416337e+00  4.362065e+00  3.783534e+00  3.192173e+00   \n",
       "\n",
       "        diagnosis  \n",
       "count  569.000000  \n",
       "mean     0.052724  \n",
       "std      0.223679  \n",
       "min      0.000000  \n",
       "25%      0.000000  \n",
       "50%      0.000000  \n",
       "75%      0.000000  \n",
       "max      1.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into x and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_final.loc[:, data_final.columns!= 'diagnosis']\n",
    "y = data_final.loc[:, data_final.columns == 'diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'PC1', u'PC2', u'PC3', u'PC4', u'PC5', u'PC6', u'PC7', u'PC8', u'PC9',\n",
       "       u'PC10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'diagnosis'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# I will show how to perform 3 methods of sampling to resolve this imbalanced dataset issue\n",
    "\n",
    "Undersampling\n",
    "Oversampling\n",
    "SMOTE - Synthetic Minority Oversampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling - The process of reducing the class instances of the MAJORITY class is called Undersampling. I will attempt to undersample the data and give a 50/50 ratio to each of the class's instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Find the number of the minority class\n",
    "number_fraud = len(data_final[data_final['diagnosis']==1])\n",
    "number_non_fraud = len(data_final[data_final['diagnosis']==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "539\n"
     ]
    }
   ],
   "source": [
    "print(number_fraud)\n",
    "print(number_non_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Find the indices of the majority and minority class\n",
    "index_non_fraud = data_final[data_final['diagnosis']==0].index\n",
    "index_fraud = data_final[data_final['diagnosis']==1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Randomly sample the majority indices with respect to the number of minority classes\n",
    "random_indices = np.random.choice(index_non_fraud, number_fraud,replace='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Concat the minority indices with the indices from step 4\n",
    "under_sample_indices = np.concatenate([index_fraud,random_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the balanced dataframe - This is the final undersampled data\n",
    "under_sample_df = data_final.iloc[under_sample_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.192787</td>\n",
       "      <td>1.948495</td>\n",
       "      <td>-1.123134</td>\n",
       "      <td>3.633519</td>\n",
       "      <td>-1.196361</td>\n",
       "      <td>1.411751</td>\n",
       "      <td>2.158566</td>\n",
       "      <td>-0.398437</td>\n",
       "      <td>-0.156939</td>\n",
       "      <td>-0.877211</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8.184812</td>\n",
       "      <td>2.700861</td>\n",
       "      <td>5.730111</td>\n",
       "      <td>-1.111752</td>\n",
       "      <td>1.044363</td>\n",
       "      <td>2.594552</td>\n",
       "      <td>0.941159</td>\n",
       "      <td>-3.322216</td>\n",
       "      <td>-0.748340</td>\n",
       "      <td>0.396778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7.098410</td>\n",
       "      <td>2.018723</td>\n",
       "      <td>-0.028998</td>\n",
       "      <td>2.587586</td>\n",
       "      <td>-2.040049</td>\n",
       "      <td>1.184395</td>\n",
       "      <td>0.601382</td>\n",
       "      <td>-1.307075</td>\n",
       "      <td>1.100766</td>\n",
       "      <td>2.286900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.059203</td>\n",
       "      <td>-0.757071</td>\n",
       "      <td>-0.349086</td>\n",
       "      <td>-1.064412</td>\n",
       "      <td>-0.746254</td>\n",
       "      <td>0.242169</td>\n",
       "      <td>0.461882</td>\n",
       "      <td>-0.291944</td>\n",
       "      <td>0.285199</td>\n",
       "      <td>0.117970</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6.230736</td>\n",
       "      <td>0.919988</td>\n",
       "      <td>0.089812</td>\n",
       "      <td>2.539194</td>\n",
       "      <td>0.061408</td>\n",
       "      <td>0.683617</td>\n",
       "      <td>1.399638</td>\n",
       "      <td>0.719857</td>\n",
       "      <td>-0.096985</td>\n",
       "      <td>0.509247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>11.668431</td>\n",
       "      <td>4.748581</td>\n",
       "      <td>2.005744</td>\n",
       "      <td>0.318663</td>\n",
       "      <td>-3.390449</td>\n",
       "      <td>4.880821</td>\n",
       "      <td>-1.156622</td>\n",
       "      <td>0.482889</td>\n",
       "      <td>-1.174156</td>\n",
       "      <td>-1.324116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>10.768867</td>\n",
       "      <td>-2.258415</td>\n",
       "      <td>0.038929</td>\n",
       "      <td>-0.389103</td>\n",
       "      <td>1.187300</td>\n",
       "      <td>-2.188205</td>\n",
       "      <td>0.035927</td>\n",
       "      <td>-0.548138</td>\n",
       "      <td>-1.648533</td>\n",
       "      <td>0.396537</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>13.055936</td>\n",
       "      <td>0.981379</td>\n",
       "      <td>0.598912</td>\n",
       "      <td>1.472849</td>\n",
       "      <td>-0.600635</td>\n",
       "      <td>1.021944</td>\n",
       "      <td>-0.096111</td>\n",
       "      <td>-0.768396</td>\n",
       "      <td>0.628199</td>\n",
       "      <td>-1.099044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>12.894156</td>\n",
       "      <td>2.316628</td>\n",
       "      <td>6.328609</td>\n",
       "      <td>1.941946</td>\n",
       "      <td>-3.159752</td>\n",
       "      <td>-0.947076</td>\n",
       "      <td>-1.297062</td>\n",
       "      <td>0.792047</td>\n",
       "      <td>-1.697187</td>\n",
       "      <td>-0.078288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>5.069511</td>\n",
       "      <td>-1.785012</td>\n",
       "      <td>1.173866</td>\n",
       "      <td>-0.693665</td>\n",
       "      <td>0.647939</td>\n",
       "      <td>-1.978205</td>\n",
       "      <td>1.598819</td>\n",
       "      <td>-0.479116</td>\n",
       "      <td>0.660529</td>\n",
       "      <td>-0.599744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>9.512109</td>\n",
       "      <td>-5.603760</td>\n",
       "      <td>-0.637010</td>\n",
       "      <td>0.224069</td>\n",
       "      <td>-0.406811</td>\n",
       "      <td>-0.836638</td>\n",
       "      <td>-0.714566</td>\n",
       "      <td>-0.803386</td>\n",
       "      <td>-2.160780</td>\n",
       "      <td>0.029222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>12.284412</td>\n",
       "      <td>-7.543003</td>\n",
       "      <td>10.112898</td>\n",
       "      <td>5.193602</td>\n",
       "      <td>-3.854904</td>\n",
       "      <td>-0.876831</td>\n",
       "      <td>5.416337</td>\n",
       "      <td>1.603539</td>\n",
       "      <td>1.862870</td>\n",
       "      <td>-2.563014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>8.403495</td>\n",
       "      <td>-4.153920</td>\n",
       "      <td>0.047269</td>\n",
       "      <td>-0.552008</td>\n",
       "      <td>-0.288754</td>\n",
       "      <td>-0.506901</td>\n",
       "      <td>0.718929</td>\n",
       "      <td>0.698901</td>\n",
       "      <td>0.159483</td>\n",
       "      <td>0.552676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>7.143536</td>\n",
       "      <td>-2.074834</td>\n",
       "      <td>1.088532</td>\n",
       "      <td>0.716401</td>\n",
       "      <td>0.819246</td>\n",
       "      <td>1.144615</td>\n",
       "      <td>-0.289528</td>\n",
       "      <td>-0.018807</td>\n",
       "      <td>1.217248</td>\n",
       "      <td>0.307438</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>6.392389</td>\n",
       "      <td>-1.823113</td>\n",
       "      <td>0.480021</td>\n",
       "      <td>-1.696381</td>\n",
       "      <td>0.556620</td>\n",
       "      <td>-0.106698</td>\n",
       "      <td>1.342353</td>\n",
       "      <td>0.265920</td>\n",
       "      <td>-0.490082</td>\n",
       "      <td>0.689182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>8.733852</td>\n",
       "      <td>3.280064</td>\n",
       "      <td>2.903765</td>\n",
       "      <td>-0.277243</td>\n",
       "      <td>-1.062141</td>\n",
       "      <td>-0.567456</td>\n",
       "      <td>0.789382</td>\n",
       "      <td>-1.434055</td>\n",
       "      <td>1.517181</td>\n",
       "      <td>-0.108104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>7.675836</td>\n",
       "      <td>-3.075397</td>\n",
       "      <td>1.482145</td>\n",
       "      <td>0.552533</td>\n",
       "      <td>0.885490</td>\n",
       "      <td>-0.082379</td>\n",
       "      <td>1.652112</td>\n",
       "      <td>0.134970</td>\n",
       "      <td>-0.242185</td>\n",
       "      <td>-0.649735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>6.590016</td>\n",
       "      <td>-1.484850</td>\n",
       "      <td>0.361490</td>\n",
       "      <td>1.188380</td>\n",
       "      <td>-0.121770</td>\n",
       "      <td>-0.892615</td>\n",
       "      <td>1.171626</td>\n",
       "      <td>-0.240672</td>\n",
       "      <td>0.401912</td>\n",
       "      <td>-0.792205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>7.182639</td>\n",
       "      <td>0.055154</td>\n",
       "      <td>2.012965</td>\n",
       "      <td>0.082733</td>\n",
       "      <td>-0.665774</td>\n",
       "      <td>0.424674</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>-0.690098</td>\n",
       "      <td>0.179511</td>\n",
       "      <td>0.440013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>7.352785</td>\n",
       "      <td>-5.242574</td>\n",
       "      <td>0.317266</td>\n",
       "      <td>0.431764</td>\n",
       "      <td>-0.706897</td>\n",
       "      <td>-1.263059</td>\n",
       "      <td>0.169177</td>\n",
       "      <td>0.379152</td>\n",
       "      <td>-0.137975</td>\n",
       "      <td>0.375923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>10.933873</td>\n",
       "      <td>-3.703543</td>\n",
       "      <td>-0.891519</td>\n",
       "      <td>2.343347</td>\n",
       "      <td>-0.489660</td>\n",
       "      <td>0.196538</td>\n",
       "      <td>-0.109972</td>\n",
       "      <td>0.219272</td>\n",
       "      <td>-1.762211</td>\n",
       "      <td>-0.462106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>6.226692</td>\n",
       "      <td>-1.389984</td>\n",
       "      <td>2.734367</td>\n",
       "      <td>-1.093228</td>\n",
       "      <td>-0.582483</td>\n",
       "      <td>0.988957</td>\n",
       "      <td>-0.798222</td>\n",
       "      <td>0.245945</td>\n",
       "      <td>-0.273979</td>\n",
       "      <td>-0.364715</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>7.247668</td>\n",
       "      <td>-3.655556</td>\n",
       "      <td>-0.155495</td>\n",
       "      <td>1.226782</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>-0.478207</td>\n",
       "      <td>0.844984</td>\n",
       "      <td>-0.636731</td>\n",
       "      <td>-0.204000</td>\n",
       "      <td>0.162580</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>16.318913</td>\n",
       "      <td>-7.775516</td>\n",
       "      <td>6.236128</td>\n",
       "      <td>2.327597</td>\n",
       "      <td>-1.712453</td>\n",
       "      <td>-1.124035</td>\n",
       "      <td>4.961466</td>\n",
       "      <td>0.888914</td>\n",
       "      <td>3.594913</td>\n",
       "      <td>-0.588572</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>5.930868</td>\n",
       "      <td>1.228054</td>\n",
       "      <td>1.721539</td>\n",
       "      <td>-0.472911</td>\n",
       "      <td>2.883555</td>\n",
       "      <td>-1.100220</td>\n",
       "      <td>2.024728</td>\n",
       "      <td>-0.484217</td>\n",
       "      <td>-0.678950</td>\n",
       "      <td>0.604959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>7.258806</td>\n",
       "      <td>-5.495717</td>\n",
       "      <td>1.911226</td>\n",
       "      <td>1.895668</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.066628</td>\n",
       "      <td>1.153598</td>\n",
       "      <td>0.992682</td>\n",
       "      <td>0.167523</td>\n",
       "      <td>-0.569722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>8.630312</td>\n",
       "      <td>-3.459727</td>\n",
       "      <td>-0.178930</td>\n",
       "      <td>1.177139</td>\n",
       "      <td>-0.023318</td>\n",
       "      <td>-0.006639</td>\n",
       "      <td>0.962153</td>\n",
       "      <td>-0.398448</td>\n",
       "      <td>-1.257571</td>\n",
       "      <td>0.849439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>4.027989</td>\n",
       "      <td>-2.941306</td>\n",
       "      <td>1.659603</td>\n",
       "      <td>0.225016</td>\n",
       "      <td>-0.513667</td>\n",
       "      <td>1.936204</td>\n",
       "      <td>-0.728319</td>\n",
       "      <td>-0.758057</td>\n",
       "      <td>-0.175909</td>\n",
       "      <td>0.270611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>8.741086</td>\n",
       "      <td>-0.573996</td>\n",
       "      <td>0.897171</td>\n",
       "      <td>0.385298</td>\n",
       "      <td>0.678675</td>\n",
       "      <td>-0.300688</td>\n",
       "      <td>0.094751</td>\n",
       "      <td>-0.733801</td>\n",
       "      <td>0.831107</td>\n",
       "      <td>0.450684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>6.438949</td>\n",
       "      <td>-3.576722</td>\n",
       "      <td>2.459696</td>\n",
       "      <td>1.177250</td>\n",
       "      <td>-0.075682</td>\n",
       "      <td>-2.375096</td>\n",
       "      <td>-0.596195</td>\n",
       "      <td>-0.035102</td>\n",
       "      <td>0.988108</td>\n",
       "      <td>0.257094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>-2.966151</td>\n",
       "      <td>0.371696</td>\n",
       "      <td>-2.066593</td>\n",
       "      <td>2.072425</td>\n",
       "      <td>0.162492</td>\n",
       "      <td>-0.438389</td>\n",
       "      <td>0.057164</td>\n",
       "      <td>0.464197</td>\n",
       "      <td>0.246344</td>\n",
       "      <td>-0.493565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>-2.630175</td>\n",
       "      <td>-0.697041</td>\n",
       "      <td>-0.583923</td>\n",
       "      <td>0.338160</td>\n",
       "      <td>0.467290</td>\n",
       "      <td>0.034850</td>\n",
       "      <td>0.120373</td>\n",
       "      <td>-0.460202</td>\n",
       "      <td>0.315878</td>\n",
       "      <td>-0.015815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-3.067841</td>\n",
       "      <td>1.136335</td>\n",
       "      <td>0.374636</td>\n",
       "      <td>-0.627159</td>\n",
       "      <td>-1.443554</td>\n",
       "      <td>-0.191823</td>\n",
       "      <td>-0.170046</td>\n",
       "      <td>-0.759426</td>\n",
       "      <td>0.241838</td>\n",
       "      <td>-0.356208</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>-1.292734</td>\n",
       "      <td>4.964712</td>\n",
       "      <td>0.345752</td>\n",
       "      <td>2.239918</td>\n",
       "      <td>-3.840422</td>\n",
       "      <td>-0.548578</td>\n",
       "      <td>-0.815276</td>\n",
       "      <td>0.987835</td>\n",
       "      <td>-0.072342</td>\n",
       "      <td>-0.053199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>-1.554925</td>\n",
       "      <td>0.979864</td>\n",
       "      <td>1.196471</td>\n",
       "      <td>-1.774470</td>\n",
       "      <td>3.499601</td>\n",
       "      <td>0.312113</td>\n",
       "      <td>0.641987</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>-1.081334</td>\n",
       "      <td>-0.610196</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>-3.003832</td>\n",
       "      <td>0.354657</td>\n",
       "      <td>1.234028</td>\n",
       "      <td>-0.717739</td>\n",
       "      <td>-1.312248</td>\n",
       "      <td>1.996849</td>\n",
       "      <td>-0.448132</td>\n",
       "      <td>-0.439460</td>\n",
       "      <td>-0.154635</td>\n",
       "      <td>-0.153393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>-2.418921</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>-0.798381</td>\n",
       "      <td>-0.071001</td>\n",
       "      <td>-0.077338</td>\n",
       "      <td>0.865480</td>\n",
       "      <td>0.107206</td>\n",
       "      <td>-0.109162</td>\n",
       "      <td>0.454210</td>\n",
       "      <td>0.491154</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-2.931352</td>\n",
       "      <td>-0.494458</td>\n",
       "      <td>-1.016977</td>\n",
       "      <td>-1.686640</td>\n",
       "      <td>-0.565639</td>\n",
       "      <td>-0.468919</td>\n",
       "      <td>-0.034276</td>\n",
       "      <td>-0.193163</td>\n",
       "      <td>0.476670</td>\n",
       "      <td>-0.680382</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-4.027825</td>\n",
       "      <td>-2.542618</td>\n",
       "      <td>0.353261</td>\n",
       "      <td>1.514380</td>\n",
       "      <td>0.666909</td>\n",
       "      <td>-0.096250</td>\n",
       "      <td>0.840159</td>\n",
       "      <td>-0.333281</td>\n",
       "      <td>-0.011429</td>\n",
       "      <td>-0.173926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.704260</td>\n",
       "      <td>-4.436989</td>\n",
       "      <td>0.307581</td>\n",
       "      <td>0.488598</td>\n",
       "      <td>0.371655</td>\n",
       "      <td>-0.291699</td>\n",
       "      <td>0.283464</td>\n",
       "      <td>0.086461</td>\n",
       "      <td>0.327840</td>\n",
       "      <td>0.033458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>-2.677958</td>\n",
       "      <td>2.316013</td>\n",
       "      <td>-0.053974</td>\n",
       "      <td>0.340561</td>\n",
       "      <td>0.450805</td>\n",
       "      <td>-0.678410</td>\n",
       "      <td>0.064325</td>\n",
       "      <td>0.970815</td>\n",
       "      <td>-0.455421</td>\n",
       "      <td>0.095435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-3.543131</td>\n",
       "      <td>-1.282046</td>\n",
       "      <td>1.018292</td>\n",
       "      <td>-0.608289</td>\n",
       "      <td>-0.219734</td>\n",
       "      <td>0.266267</td>\n",
       "      <td>0.454121</td>\n",
       "      <td>0.124086</td>\n",
       "      <td>0.259888</td>\n",
       "      <td>-0.434959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.779625</td>\n",
       "      <td>2.776829</td>\n",
       "      <td>-0.942733</td>\n",
       "      <td>-3.074450</td>\n",
       "      <td>-0.694557</td>\n",
       "      <td>-1.201339</td>\n",
       "      <td>0.628777</td>\n",
       "      <td>0.457956</td>\n",
       "      <td>0.251804</td>\n",
       "      <td>0.022276</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-1.978048</td>\n",
       "      <td>-1.842558</td>\n",
       "      <td>-0.277340</td>\n",
       "      <td>0.549617</td>\n",
       "      <td>-0.206950</td>\n",
       "      <td>-0.283953</td>\n",
       "      <td>-0.553764</td>\n",
       "      <td>-0.913637</td>\n",
       "      <td>-0.222858</td>\n",
       "      <td>0.378665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>-3.172658</td>\n",
       "      <td>-2.088903</td>\n",
       "      <td>-0.978795</td>\n",
       "      <td>0.387214</td>\n",
       "      <td>1.419280</td>\n",
       "      <td>1.338290</td>\n",
       "      <td>0.537631</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.786568</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-5.565961</td>\n",
       "      <td>-0.477205</td>\n",
       "      <td>4.127514</td>\n",
       "      <td>-2.352633</td>\n",
       "      <td>-1.051719</td>\n",
       "      <td>2.093515</td>\n",
       "      <td>1.167000</td>\n",
       "      <td>-3.953902</td>\n",
       "      <td>-2.059445</td>\n",
       "      <td>-2.672307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>6.182162</td>\n",
       "      <td>5.107950</td>\n",
       "      <td>0.520922</td>\n",
       "      <td>0.940795</td>\n",
       "      <td>-0.605978</td>\n",
       "      <td>2.461520</td>\n",
       "      <td>-1.468676</td>\n",
       "      <td>0.268291</td>\n",
       "      <td>-0.810210</td>\n",
       "      <td>-1.064902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2.611336</td>\n",
       "      <td>1.561417</td>\n",
       "      <td>-0.218253</td>\n",
       "      <td>-0.492541</td>\n",
       "      <td>1.104642</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>-0.863824</td>\n",
       "      <td>0.204923</td>\n",
       "      <td>-0.356616</td>\n",
       "      <td>-0.411401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.699928</td>\n",
       "      <td>2.352404</td>\n",
       "      <td>-3.078110</td>\n",
       "      <td>-0.066272</td>\n",
       "      <td>-1.056525</td>\n",
       "      <td>-0.282072</td>\n",
       "      <td>-0.160830</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.591834</td>\n",
       "      <td>-0.105238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>7.236165</td>\n",
       "      <td>-0.035719</td>\n",
       "      <td>-2.840988</td>\n",
       "      <td>0.038116</td>\n",
       "      <td>-2.454659</td>\n",
       "      <td>2.500060</td>\n",
       "      <td>-0.862200</td>\n",
       "      <td>-0.089664</td>\n",
       "      <td>-0.424333</td>\n",
       "      <td>0.764129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-4.038235</td>\n",
       "      <td>-0.240472</td>\n",
       "      <td>-1.328205</td>\n",
       "      <td>2.440160</td>\n",
       "      <td>0.276904</td>\n",
       "      <td>1.693632</td>\n",
       "      <td>0.414465</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>-0.010579</td>\n",
       "      <td>0.092718</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-2.151191</td>\n",
       "      <td>-1.923695</td>\n",
       "      <td>-1.180370</td>\n",
       "      <td>-1.113288</td>\n",
       "      <td>0.448339</td>\n",
       "      <td>0.929098</td>\n",
       "      <td>0.042077</td>\n",
       "      <td>-0.048339</td>\n",
       "      <td>0.667794</td>\n",
       "      <td>0.390467</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-2.786015</td>\n",
       "      <td>2.311129</td>\n",
       "      <td>0.472711</td>\n",
       "      <td>-1.607429</td>\n",
       "      <td>-1.612387</td>\n",
       "      <td>-1.189566</td>\n",
       "      <td>0.169398</td>\n",
       "      <td>0.029765</td>\n",
       "      <td>-0.111827</td>\n",
       "      <td>-0.271385</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>-2.154133</td>\n",
       "      <td>-0.829710</td>\n",
       "      <td>0.564881</td>\n",
       "      <td>-3.011724</td>\n",
       "      <td>0.566345</td>\n",
       "      <td>-0.550507</td>\n",
       "      <td>-0.483990</td>\n",
       "      <td>0.893378</td>\n",
       "      <td>0.435685</td>\n",
       "      <td>0.243691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-1.929831</td>\n",
       "      <td>0.892874</td>\n",
       "      <td>0.042341</td>\n",
       "      <td>-0.559166</td>\n",
       "      <td>-1.280098</td>\n",
       "      <td>0.116793</td>\n",
       "      <td>-0.468333</td>\n",
       "      <td>0.667733</td>\n",
       "      <td>0.265807</td>\n",
       "      <td>0.619660</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>4.949854</td>\n",
       "      <td>3.005842</td>\n",
       "      <td>-1.754172</td>\n",
       "      <td>-0.671808</td>\n",
       "      <td>2.864841</td>\n",
       "      <td>-0.307164</td>\n",
       "      <td>-0.649604</td>\n",
       "      <td>-0.204631</td>\n",
       "      <td>0.499684</td>\n",
       "      <td>-0.382684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>-3.647527</td>\n",
       "      <td>-1.240983</td>\n",
       "      <td>1.386627</td>\n",
       "      <td>1.613851</td>\n",
       "      <td>-0.173367</td>\n",
       "      <td>0.597055</td>\n",
       "      <td>-0.293867</td>\n",
       "      <td>0.407615</td>\n",
       "      <td>-0.043224</td>\n",
       "      <td>-0.609518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.357732</td>\n",
       "      <td>2.128044</td>\n",
       "      <td>0.708114</td>\n",
       "      <td>0.184764</td>\n",
       "      <td>-0.102304</td>\n",
       "      <td>0.563123</td>\n",
       "      <td>-0.987397</td>\n",
       "      <td>-0.529845</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.145563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.357732</td>\n",
       "      <td>2.128044</td>\n",
       "      <td>0.708114</td>\n",
       "      <td>0.184764</td>\n",
       "      <td>-0.102304</td>\n",
       "      <td>0.563123</td>\n",
       "      <td>-0.987397</td>\n",
       "      <td>-0.529845</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>0.145563</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.699928</td>\n",
       "      <td>2.352404</td>\n",
       "      <td>-3.078110</td>\n",
       "      <td>-0.066272</td>\n",
       "      <td>-1.056525</td>\n",
       "      <td>-0.282072</td>\n",
       "      <td>-0.160830</td>\n",
       "      <td>0.019131</td>\n",
       "      <td>0.591834</td>\n",
       "      <td>-0.105238</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           PC1       PC2        PC3       PC4       PC5       PC6       PC7  \\\n",
       "0     9.192787  1.948495  -1.123134  3.633519 -1.196361  1.411751  2.158566   \n",
       "12    8.184812  2.700861   5.730111 -1.111752  1.044363  2.594552  0.941159   \n",
       "25    7.098410  2.018723  -0.028998  2.587586 -2.040049  1.184395  0.601382   \n",
       "30    6.059203 -0.757071  -0.349086 -1.064412 -0.746254  0.242169  0.461882   \n",
       "77    6.230736  0.919988   0.089812  2.539194  0.061408  0.683617  1.399638   \n",
       "78   11.668431  4.748581   2.005744  0.318663 -3.390449  4.880821 -1.156622   \n",
       "82   10.768867 -2.258415   0.038929 -0.389103  1.187300 -2.188205  0.035927   \n",
       "108  13.055936  0.981379   0.598912  1.472849 -0.600635  1.021944 -0.096111   \n",
       "122  12.894156  2.316628   6.328609  1.941946 -3.159752 -0.947076 -1.297062   \n",
       "168   5.069511 -1.785012   1.173866 -0.693665  0.647939 -1.978205  1.598819   \n",
       "180   9.512109 -5.603760  -0.637010  0.224069 -0.406811 -0.836638 -0.714566   \n",
       "212  12.284412 -7.543003  10.112898  5.193602 -3.854904 -0.876831  5.416337   \n",
       "236   8.403495 -4.153920   0.047269 -0.552008 -0.288754 -0.506901  0.718929   \n",
       "250   7.143536 -2.074834   1.088532  0.716401  0.819246  1.144615 -0.289528   \n",
       "256   6.392389 -1.823113   0.480021 -1.696381  0.556620 -0.106698  1.342353   \n",
       "258   8.733852  3.280064   2.903765 -0.277243 -1.062141 -0.567456  0.789382   \n",
       "272   7.675836 -3.075397   1.482145  0.552533  0.885490 -0.082379  1.652112   \n",
       "300   6.590016 -1.484850   0.361490  1.188380 -0.121770 -0.892615  1.171626   \n",
       "302   7.182639  0.055154   2.012965  0.082733 -0.665774  0.424674  0.801556   \n",
       "339   7.352785 -5.242574   0.317266  0.431764 -0.706897 -1.263059  0.169177   \n",
       "352  10.933873 -3.703543  -0.891519  2.343347 -0.489660  0.196538 -0.109972   \n",
       "366   6.226692 -1.389984   2.734367 -1.093228 -0.582483  0.988957 -0.798222   \n",
       "369   7.247668 -3.655556  -0.155495  1.226782  0.296667 -0.478207  0.844984   \n",
       "461  16.318913 -7.775516   6.236128  2.327597 -1.712453 -1.124035  4.961466   \n",
       "468   5.930868  1.228054   1.721539 -0.472911  2.883555 -1.100220  2.024728   \n",
       "503   7.258806 -5.495717   1.911226  1.895668  0.395000  0.066628  1.153598   \n",
       "521   8.630312 -3.459727  -0.178930  1.177139 -0.023318 -0.006639  0.962153   \n",
       "533   4.027989 -2.941306   1.659603  0.225016 -0.513667  1.936204 -0.728319   \n",
       "563   8.741086 -0.573996   0.897171  0.385298  0.678675 -0.300688  0.094751   \n",
       "564   6.438949 -3.576722   2.459696  1.177250 -0.075682 -2.375096 -0.596195   \n",
       "120  -2.966151  0.371696  -2.066593  2.072425  0.162492 -0.438389  0.057164   \n",
       "74   -2.630175 -0.697041  -0.583923  0.338160  0.467290  0.034850  0.120373   \n",
       "338  -3.067841  1.136335   0.374636 -0.627159 -1.443554 -0.191823 -0.170046   \n",
       "520  -1.292734  4.964712   0.345752  2.239918 -3.840422 -0.548578 -0.815276   \n",
       "382  -1.554925  0.979864   1.196471 -1.774470  3.499601  0.312113  0.641987   \n",
       "289  -3.003832  0.354657   1.234028 -0.717739 -1.312248  1.996849 -0.448132   \n",
       "155  -2.418921  0.005842  -0.798381 -0.071001 -0.077338  0.865480  0.107206   \n",
       "410  -2.931352 -0.494458  -1.016977 -1.686640 -0.565639 -0.468919 -0.034276   \n",
       "309  -4.027825 -2.542618   0.353261  1.514380  0.666909 -0.096250  0.840159   \n",
       "70    2.704260 -4.436989   0.307581  0.488598  0.371655 -0.291699  0.283464   \n",
       "547  -2.677958  2.316013  -0.053974  0.340561  0.450805 -0.678410  0.064325   \n",
       "50   -3.543131 -1.282046   1.018292 -0.608289 -0.219734  0.266267  0.454121   \n",
       "193   1.779625  2.776829  -0.942733 -3.074450 -0.694557 -1.201339  0.628777   \n",
       "169  -1.978048 -1.842558  -0.277340  0.549617 -0.206950 -0.283953 -0.553764   \n",
       "477  -3.172658 -2.088903  -0.978795  0.387214  1.419280  1.338290  0.537631   \n",
       "192  -5.565961 -0.477205   4.127514 -2.352633 -1.051719  2.093515  1.167000   \n",
       "351   6.182162  5.107950   0.520922  0.940795 -0.605978  2.461520 -1.468676   \n",
       "194   2.611336  1.561417  -0.218253 -0.492541  1.104642  0.005728 -0.863824   \n",
       "47    1.699928  2.352404  -3.078110 -0.066272 -1.056525 -0.282072 -0.160830   \n",
       "323   7.236165 -0.035719  -2.840988  0.038116 -2.454659  2.500060 -0.862200   \n",
       "313  -4.038235 -0.240472  -1.328205  2.440160  0.276904  1.693632  0.414465   \n",
       "40   -2.151191 -1.923695  -1.180370 -1.113288  0.448339  0.929098  0.042077   \n",
       "66   -2.786015  2.311129   0.472711 -1.607429 -1.612387 -1.189566  0.169398   \n",
       "554  -2.154133 -0.829710   0.564881 -3.011724  0.566345 -0.550507 -0.483990   \n",
       "415  -1.929831  0.892874   0.042341 -0.559166 -1.280098  0.116793 -0.468333   \n",
       "430   4.949854  3.005842  -1.754172 -0.671808  2.864841 -0.307164 -0.649604   \n",
       "404  -3.647527 -1.240983   1.386627  1.613851 -0.173367  0.597055 -0.293867   \n",
       "356   0.357732  2.128044   0.708114  0.184764 -0.102304  0.563123 -0.987397   \n",
       "356   0.357732  2.128044   0.708114  0.184764 -0.102304  0.563123 -0.987397   \n",
       "47    1.699928  2.352404  -3.078110 -0.066272 -1.056525 -0.282072 -0.160830   \n",
       "\n",
       "          PC8       PC9      PC10  diagnosis  \n",
       "0   -0.398437 -0.156939 -0.877211          1  \n",
       "12  -3.322216 -0.748340  0.396778          1  \n",
       "25  -1.307075  1.100766  2.286900          1  \n",
       "30  -0.291944  0.285199  0.117970          1  \n",
       "77   0.719857 -0.096985  0.509247          1  \n",
       "78   0.482889 -1.174156 -1.324116          1  \n",
       "82  -0.548138 -1.648533  0.396537          1  \n",
       "108 -0.768396  0.628199 -1.099044          1  \n",
       "122  0.792047 -1.697187 -0.078288          1  \n",
       "168 -0.479116  0.660529 -0.599744          1  \n",
       "180 -0.803386 -2.160780  0.029222          1  \n",
       "212  1.603539  1.862870 -2.563014          1  \n",
       "236  0.698901  0.159483  0.552676          1  \n",
       "250 -0.018807  1.217248  0.307438          1  \n",
       "256  0.265920 -0.490082  0.689182          1  \n",
       "258 -1.434055  1.517181 -0.108104          1  \n",
       "272  0.134970 -0.242185 -0.649735          1  \n",
       "300 -0.240672  0.401912 -0.792205          1  \n",
       "302 -0.690098  0.179511  0.440013          1  \n",
       "339  0.379152 -0.137975  0.375923          1  \n",
       "352  0.219272 -1.762211 -0.462106          1  \n",
       "366  0.245945 -0.273979 -0.364715          1  \n",
       "369 -0.636731 -0.204000  0.162580          1  \n",
       "461  0.888914  3.594913 -0.588572          1  \n",
       "468 -0.484217 -0.678950  0.604959          1  \n",
       "503  0.992682  0.167523 -0.569722          1  \n",
       "521 -0.398448 -1.257571  0.849439          1  \n",
       "533 -0.758057 -0.175909  0.270611          1  \n",
       "563 -0.733801  0.831107  0.450684          1  \n",
       "564 -0.035102  0.988108  0.257094          1  \n",
       "120  0.464197  0.246344 -0.493565          0  \n",
       "74  -0.460202  0.315878 -0.015815          0  \n",
       "338 -0.759426  0.241838 -0.356208          0  \n",
       "520  0.987835 -0.072342 -0.053199          0  \n",
       "382  0.019453 -1.081334 -0.610196          0  \n",
       "289 -0.439460 -0.154635 -0.153393          0  \n",
       "155 -0.109162  0.454210  0.491154          0  \n",
       "410 -0.193163  0.476670 -0.680382          0  \n",
       "309 -0.333281 -0.011429 -0.173926          0  \n",
       "70   0.086461  0.327840  0.033458          0  \n",
       "547  0.970815 -0.455421  0.095435          0  \n",
       "50   0.124086  0.259888 -0.434959          0  \n",
       "193  0.457956  0.251804  0.022276          0  \n",
       "169 -0.913637 -0.222858  0.378665          0  \n",
       "477  0.042053 -0.040887  0.786568          0  \n",
       "192 -3.953902 -2.059445 -2.672307          0  \n",
       "351  0.268291 -0.810210 -1.064902          0  \n",
       "194  0.204923 -0.356616 -0.411401          0  \n",
       "47   0.019131  0.591834 -0.105238          0  \n",
       "323 -0.089664 -0.424333  0.764129          0  \n",
       "313  0.105634 -0.010579  0.092718          0  \n",
       "40  -0.048339  0.667794  0.390467          0  \n",
       "66   0.029765 -0.111827 -0.271385          0  \n",
       "554  0.893378  0.435685  0.243691          0  \n",
       "415  0.667733  0.265807  0.619660          0  \n",
       "430 -0.204631  0.499684 -0.382684          0  \n",
       "404  0.407615 -0.043224 -0.609518          0  \n",
       "356 -0.529845  0.008744  0.145563          0  \n",
       "356 -0.529845  0.008744  0.145563          0  \n",
       "47   0.019131  0.591834 -0.105238          0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0L: 30, 1L: 30})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(under_sample_df['diagnosis'])\n",
    "#Now we can see that both the classes are in same proportion\n",
    "#Majority classes are undersampled to the no. of minority classes count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, split the data into x, y, train, and test\n",
    "x_under = under_sample_df.loc[:, under_sample_df.columns!='diagnosis']\n",
    "y_under = under_sample_df.loc[:, under_sample_df.columns=='diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run a logistic regression for Under sampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_under=LogisticRegression()\n",
    "x_under_train, x_under_test, y_under_train, y_under_test = train_test_split(x_under, y_under, test_size=0.3, random_state=1)\n",
    "lr_under.fit(x_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_predict_train = lr_under.predict(x_under_train)\n",
    "under_predict_test = lr_under.predict(x_under_test)\n",
    "under_predict_utest = lr_under.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "lr_under_accuracy_train = accuracy_score(y_under_train,under_predict_train)\n",
    "lr_under_recall_train = recall_score(y_under_train,under_predict_train)\n",
    "lr_under_precision_train = recall_score(y_under_train,under_predict_train)\n",
    "lr_under_accuracy_test = accuracy_score(y_under_test,under_predict_test)\n",
    "lr_under_recall_test = recall_score(y_under_test,under_predict_test)\n",
    "lr_under_precision_test = recall_score(y_under_test,under_predict_test)\n",
    "print(lr_under_accuracy_train)\n",
    "print(lr_under_recall_train)\n",
    "print(lr_under_precision_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(lr_under_accuracy_test)\n",
    "print(lr_under_recall_test)\n",
    "print(lr_under_precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8601398601398601\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#For Unseen Test Data\n",
    "lr_under_accuracy_test = accuracy_score(y_test,under_predict_utest)\n",
    "lr_under_recall_test = recall_score(y_test,under_predict_utest)\n",
    "lr_under_precision_test = recall_score(y_test,under_predict_utest)\n",
    "print(lr_under_accuracy_test)\n",
    "print(lr_under_recall_test)\n",
    "print(lr_under_precision_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that, undersampled model is performing well on the Train Data, but not on the Test ans Unseen Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling - \n",
    "The process of increasin the class instances of the MINORITY class is called Oversampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample function is used to oversample the 1's. Rows with target variable 1 will be oversampled to match with No. of 0's count.\n",
    "fraud_sample = data_final[data_final['diagnosis']==1].sample(number_non_fraud, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1L: 539})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(fraud_sample['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new dataframe containing only non-fraud data\n",
    "df_fraud = data_final[data_final['diagnosis']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_sample_df = pd.concat([fraud_sample,df_fraud], axis=0)\n",
    "len(over_sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0L: 539, 1L: 539})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(over_sample_df['diagnosis'])\n",
    "#Now we can see both our 0's and 1's are in same Proportion. Basically we have oversampled our 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into x,y, train, and test\n",
    "x_over = data_final.loc[:,over_sample_df.columns!='diagnosis']\n",
    "y_over = data_final.loc[:,over_sample_df.columns=='diagnosis']\n",
    "x_over_train, x_over_test, y_over_train, y_over_test = train_test_split(x_over, y_over, test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_over = LogisticRegression()\n",
    "lr_over.fit(x_over_train,y_over_train)\n",
    "lr_over_predict_test=lr_over.predict(x_over_test)\n",
    "lr_over_predict_train=lr_over.predict(x_over_train)\n",
    "lr_over_predict_utest=lr_over.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9798994974874372\n",
      "0.7916666666666666\n",
      "0.8636363636363636\n"
     ]
    }
   ],
   "source": [
    "lr_over_accuracy_train = accuracy_score(y_over_train,lr_over_predict_train)\n",
    "lr_over_recall_train = recall_score(y_over_train,lr_over_predict_train)\n",
    "lr_over_precision_train = precision_score(y_over_train,lr_over_predict_train)\n",
    "print(lr_over_accuracy_train)\n",
    "print(lr_over_recall_train)\n",
    "print(lr_over_precision_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9883040935672515\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "lr_over_accuracy_test = accuracy_score(y_over_test,lr_over_predict_test)\n",
    "lr_over_recall_test = recall_score(y_over_test,lr_over_predict_test)\n",
    "lr_over_precision_test = recall_score(y_over_test,lr_over_predict_test)\n",
    "print(lr_over_accuracy_test)\n",
    "print(lr_over_recall_test)\n",
    "print(lr_over_precision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9883040935672515\n",
      "0.8333333333333334\n",
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "#For unseen Test Data\n",
    "lr_over_accuracy_utest = accuracy_score(y_test,lr_over_predict_utest)\n",
    "lr_over_recall_utest = recall_score(y_test,lr_over_predict_utest)\n",
    "lr_over_precision_utest = recall_score(y_test,lr_over_predict_utest)\n",
    "print(lr_over_accuracy_test)\n",
    "print(lr_over_recall_test)\n",
    "print(lr_over_precision_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE - Syntetic Minority Over Sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The right way to work on imbalanced data and SMOTE is to oversample only on the training data, and leave the test data unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sm_train, x_sm_test, y_sm_train,y_sm_test = train_test_split(x_train, y_train, test_size = 0.3, random_state=3)\n",
    "x_train_res, y_train_res = sm.fit_sample(x_sm_train, y_sm_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 280, 1: 280})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9832214765100671\n",
      "1.0\n",
      "0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "lr_smote = LogisticRegression()\n",
    "lr_smote.fit(x_train_res, y_train_res)\n",
    "#predict on the train data\n",
    "lr_smote_predict_train = lr_smote.predict(x_sm_train)\n",
    "#print accuracy and recall on train data\n",
    "print(accuracy_score(y_sm_train,lr_smote_predict_train))\n",
    "print(recall_score(y_sm_train,lr_smote_predict_train))\n",
    "print(precision_score(y_sm_train,lr_smote_predict_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.953125\n",
      "1.0\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#predict on the test data\n",
    "lr_smote_predict = lr_smote.predict(x_sm_test)\n",
    "#print accuracy and recall on train data\n",
    "print(accuracy_score(y_sm_test,lr_smote_predict))\n",
    "print(recall_score(y_sm_test,lr_smote_predict))\n",
    "print(precision_score(y_sm_test,lr_smote_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.972027972027972\n",
      "1.0\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "#predict on the Unseen test data\n",
    "lr_smote_predict_utest = lr_smote.predict(x_test)\n",
    "print(accuracy_score(y_test,lr_smote_predict_utest))\n",
    "print(recall_score(y_test,lr_smote_predict_utest))\n",
    "print(precision_score(y_test,lr_smote_predict_utest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the accuracy and recall score for are almost equal for the test data and un seen test data but precision score is less compared to the Oversampling.\n",
    "In this problem, Oversampling Techinique perfomrs much better than the SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
